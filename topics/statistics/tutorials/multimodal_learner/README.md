# Galaxy Multimodal Learner - Building a Multimodal Deep Learning Model using the HANCOCK Dataset

This tutorial demonstrates how to use the GLEAM Multimodal Learner tool in Galaxy to build a multimodal deep learning classifier for predicting 3-year recurrence in head and neck cancer patients using the HANCOCK dataset.

## Learning Objectives

- Use the HANCOCK dataset to build a multimodal prediction model for head and neck cancer recurrence
- Train a deep learning classifier using the GLEAM Multimodal Learner tool in Galaxy
- Evaluate the model's performance using standard machine learning metrics
- Understand how multimodal learning can leverage complementary information from different data types

## Dataset

The tutorial uses the HANCOCK (Head and Neck Cancer Outcome Cohort) dataset, which includes:
- Clinical and pathological features (tabular data)
- Tissue microarray (TMA) images with CD3 and CD8 immunohistochemistry staining
- ICD-10 diagnostic codes (text data)
- 3-year recurrence outcome labels

The preprocessed dataset is available on Zenodo: https://zenodo.org/records/17727354

## Prerequisites

- Basic understanding of machine learning concepts
- Familiarity with Galaxy interface
- Understanding of cancer biology and clinical data (helpful but not required)

## Time Estimation

45 minutes

## Contributors

- Khai Dang (@dangkhai)
- Paulo Cilas Jr (@paulocilasjr)
- Junhao Chiu (@qchiujunhao)
- Jeremy Goecks (@jgoecks)

## Citation

If you use this tutorial or the HANCOCK dataset, please cite:

> DÃ¶rrich, M., Balk, M., Heusinger, T. et al. A multimodal dataset for precision oncology in head and neck cancer. *Nat Commun* 16, 7163 (2025). https://doi.org/10.1038/s41467-025-62386-6

